{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network with a Single Hidden Layer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPh-e-9CEKaf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM2uaxmHFO1-"
      },
      "source": [
        "**DEFINE THE NEURAL NETWORK STRUCTURE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6fP8qTaFpU8"
      },
      "source": [
        "def layer_sizes(inputs, outputs, hidden_layer_dimension):\r\n",
        "  size_input = inputs.shape[0] # size of the input layer\r\n",
        "  size_output = outputs.shape[0] # size of the input layer\r\n",
        "  size_hidden = hidden_layer_dimension\r\n",
        "  return size_input, size_output, size_hidden"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqaG_zvBGRhd"
      },
      "source": [
        "**INITIALIZE PARAMETERS RANDOMLY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE977gDEGVA4"
      },
      "source": [
        "def initialize_parameters(inputs, outputs, hidden_layer_dimension):\r\n",
        "  size_input, size_output, size_hidden = layer_sizes(inputs, outputs, hidden_layer_dimension)\r\n",
        "  \r\n",
        "  # weight and bias vector for the hidden layer = w1 and b1\r\n",
        "  W1 = np.random.randn(size_hidden, size_input) * 0.01\r\n",
        "  b1 = np.zeros((size_hidden, 1))\r\n",
        "  \r\n",
        "  # weight and bias vector for the output layer = w2 and b2\r\n",
        "  W2 = np.random.randn(size_output, size_hidden) * 0.01\r\n",
        "  b2 = np.zeros((size_output, 1))\r\n",
        "\r\n",
        "  return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}  # dictionary to keep the parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtsrl89kI5Al"
      },
      "source": [
        "**FORWARD PROPAGATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvcQjurDf0_t"
      },
      "source": [
        "def sigmoid(x):\r\n",
        "   return 1/(1+np.exp(-x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK7loyyyI_fN"
      },
      "source": [
        "def forward_propagation(inputs, parameters):\r\n",
        "  Z1 = np.dot(parameters[\"W1\"], X) + parameters[\"b1\"]\r\n",
        "  A1 = np.tnah(Z1)\r\n",
        "  Z2 = np.dot(parameters[\"W2\"], A1) + parameters[\"b2\"]\r\n",
        "  A2 = sigmoid(Z2)  # y_hat\r\n",
        "  return A2, {\"Z1\": Z1,  \"A1\": A1,  \"Z2\": Z2,  \"A2\": A2} # dictionary to keep A and Z values / cache"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWYfJt_zKcMN"
      },
      "source": [
        "**CROSS-ENTROPY COST FUNCTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcT63nH2KhDg"
      },
      "source": [
        "def compute_cost(y_hat, outputs, parameters):\r\n",
        "  number_of_examples = outputs.shape[0]\r\n",
        "  cost = (-1 / number_of_examples) * (np.multiply(np.log(y_hat), outputs) + np.multiply((1 -outputs), np.log(1 -y_hat)))\r\n",
        "  cost = np.squeeze(cost)\r\n",
        "  return cost"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS7OKYc4MdSf"
      },
      "source": [
        "**BACKWARD PROPOGATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx-Har4tMmtQ"
      },
      "source": [
        "def backward_propogation(inputs, outputs, parameters, cache):\r\n",
        "  # retreive parameters and cache\r\n",
        "  W1 = parameters[\"W1\"]\r\n",
        "  W2 = parameters[\"W2\"]\r\n",
        "  A1 = cache[\"A1\"]\r\n",
        "  A2 = cache[\"A2\"]\r\n",
        "  # calculate dW1, db1, dW2, db2 - backward propogation\r\n",
        "  dZ2= A2 - outputs\r\n",
        "  dW2 = (1 / m) * np.dot(dZ2, A1.T)\r\n",
        "  db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\r\n",
        "  dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\r\n",
        "  dW1 = (1 / m) * np.dot(dZ1, X.T)\r\n",
        "  db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\r\n",
        "\r\n",
        "  return {\"dW1\": dW1, \"db1\": db1,  \"dW2\": dW2, \"db2\": db2}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ki-RyEdMfnO"
      },
      "source": [
        "**UPDATING THE PARAMETERS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dA2I4AHQwvu"
      },
      "source": [
        "def update_parameters(parameters, gradients, learning_rate):\r\n",
        "    # retreive the parameters\r\n",
        "    W1 = parameters[\"W1\"]\r\n",
        "    b1 = parameters[\"b1\"]\r\n",
        "    W2 = parameters[\"W2\"]\r\n",
        "    b2 = parameters[\"b2\"]\r\n",
        "   # update the parameters with respect to their gradients\r\n",
        "    W1 = W1 - learning_rate * gradients[\"dW1\"]\r\n",
        "    b1 = b1 - learning_rate * gradients[\"db1\"]\r\n",
        "    W2 = W2 -learning_rate * gradients[\"dW2\"]\r\n",
        "    b2 = b2 - learning_rate * gradients[\"db2\"]\r\n",
        "\r\n",
        "    return {\"W1\": W1, \"b1\": b1, \"W2\": W2, \"b2\": b2}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nALaiDnuMiMF"
      },
      "source": [
        "**TRAININING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GWmKIb0f-GR"
      },
      "source": [
        "def train_model(inputs, outputs, hidden_layer_dimension, num_iterations = 10000):\r\n",
        "    # initalize parameters\r\n",
        "    parameters = intialize_parameters(inputs, outputs, hidden_layer_dimension)\r\n",
        "    for i in range(num_iterations):\r\n",
        "        A2, cache = forward_propagation(inputs, parameters) # forward propagate\r\n",
        "        cost = compute_cost(A2, outputs, parameters) \r\n",
        "        grads = backward_propagation(parameters, cache, inputs, outputs) # backward propagate\r\n",
        "        parameters = update_parameters(parameters, grads) # update parameters\r\n",
        "    return parameters"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxdd8uHJhYkq"
      },
      "source": [
        "**MAKING PREDICTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9YKSsZBhbdw"
      },
      "source": [
        "def making_predictions(inputs, parameters):\r\n",
        "    A2, cache = forward_propagation(inputs, parameters)\r\n",
        "    return A2 > 0.5"
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}